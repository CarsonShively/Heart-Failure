{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline model\n",
        "\n",
        "The data had multiple linear features making logistic regression a good for baseline interpretability."
      ],
      "metadata": {
        "id": "6mWQYccge3em"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.pipeline\")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator, TransformerMixin, _SetOutputMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
        "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
        "from sklearn.metrics import (\n",
        "    make_scorer,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import shap\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.validation import check_is_fitted"
      ],
      "metadata": {
        "id": "A-ZW0AkxhgAS"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Z7woaLMuduGW"
      },
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/CarsonShively/Heart-Failure/refs/heads/main/data/heart_failure.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "X = df.drop('DEATH_EVENT', axis=1)\n",
        "y = df['DEATH_EVENT']\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom classes"
      ],
      "metadata": {
        "id": "MD2HfCIJ5HeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BinaryInt64Cleaner(BaseEstimator, TransformerMixin):\n",
        "    def set_output(self, *, transform=None):\n",
        "        return self\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = X.copy()\n",
        "\n",
        "        for col in X.columns:\n",
        "            X[col] = pd.to_numeric(X[col], errors='coerce').astype('Int64')\n",
        "            X[col] = X[col].where(X[col].isin([0, 1]), pd.NA)\n",
        "\n",
        "        return X\n",
        "\n",
        "class ConvertToInt(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = X.copy()\n",
        "\n",
        "        for col in X.columns:\n",
        "            X[col] = X[col].astype(int)\n",
        "\n",
        "        return X\n",
        "\n",
        "class CoerceToFloat(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = X.copy()\n",
        "        for col in X.columns:\n",
        "            X[col] = X[col].astype(float)\n",
        "        return X\n",
        "\n",
        "class OutlierClipper(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, columns=None, lower_quantile=0.01, upper_quantile=0.99):\n",
        "        self.columns = columns\n",
        "        self.lower_quantile = lower_quantile\n",
        "        self.upper_quantile = upper_quantile\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        X = pd.DataFrame(X)\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        self.lower_bounds_ = {\n",
        "            col: X[col].quantile(self.lower_quantile) for col in X.columns\n",
        "        }\n",
        "        self.upper_bounds_ = {\n",
        "            col: X[col].quantile(self.upper_quantile) for col in X.columns\n",
        "        }\n",
        "        return self\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = pd.DataFrame(X).copy()\n",
        "\n",
        "        for col in X.columns:\n",
        "            X[col] = X[col].clip(self.lower_bounds_[col], self.upper_bounds_[col])\n",
        "\n",
        "        return X"
      ],
      "metadata": {
        "id": "cG56dD5D5I1A"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binary features\n",
        "\n",
        "1. Make all values that are not 0 or 1 classified as < NaN > for imputation.\n",
        "2. 0 represents the absence of a characteristic, making it a safe default for imputation.\n",
        "4. Mode is a safe imputation for a sex feature in a baseline model.\n",
        "3. Convert back to int to remain consistent."
      ],
      "metadata": {
        "id": "g6wo6OEqi7m-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binary_pipeline = Pipeline(steps=[\n",
        "    ('cleaner', BinaryInt64Cleaner()),\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
        "    ('to_int', ConvertToInt())\n",
        "])"
      ],
      "metadata": {
        "id": "Kj3_XVrk7s4_"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sex feature"
      ],
      "metadata": {
        "id": "5DMO0ljI-l_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sex_pipeline = Pipeline(steps=[\n",
        "    ('cleaner', BinaryInt64Cleaner()),\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('to_int', ConvertToInt())\n",
        "])"
      ],
      "metadata": {
        "id": "HdcmC5-2-nZ6"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Numeric features\n",
        "1. Coerce to float so that all NaNs are properly classified as np.nan for imputation.\n",
        "2. Median is a safe imputation strategy for these numeric features.\n",
        "3. Apply skew-reducing transformations identified during EDA.\n",
        "4. Clip outliers at the (0.01) and (0.99) quantiles.\n",
        "5. Add squared features to capture non-linear relationships.\n",
        "6. Scale the features for model compatibility and convergence."
      ],
      "metadata": {
        "id": "icFsslNs2j2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "basic_numeric_pipeline = Pipeline([\n",
        "    ('float', CoerceToFloat()),\n",
        "    ('impute_num', SimpleImputer(strategy='median')),\n",
        "    ('clip', OutlierClipper()),\n",
        "    ('scale', StandardScaler())\n",
        "])\n",
        "\n",
        "log_numeric_pipeline = Pipeline([\n",
        "    ('float', CoerceToFloat()),\n",
        "    ('impute_num', SimpleImputer(strategy='median')),\n",
        "    ('log_transform', FunctionTransformer(\n",
        "    func=np.log1p,\n",
        "    feature_names_out='one-to-one'\n",
        "    )),\n",
        "    ('clip', OutlierClipper()),\n",
        "    ('scale', StandardScaler())\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OovySDB82o0K"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline"
      ],
      "metadata": {
        "id": "K5Bknmp-r4ma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binary_cols = [\n",
        "    'anaemia', 'diabetes', 'high_blood_pressure', 'smoking'\n",
        "]\n",
        "\n",
        "basic_numeric_features = [\n",
        "    'age',\n",
        "    'ejection_fraction',\n",
        "    'serum_sodium',\n",
        "    'time'\n",
        "]\n",
        "\n",
        "log_numeric_features = [\n",
        "    'creatinine_phosphokinase',\n",
        "    'platelets',\n",
        "    'serum_creatinine'\n",
        "]\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('bin', binary_pipeline, binary_cols),\n",
        "    ('sex', sex_pipeline, ['sex']),\n",
        "    ('basic_num', basic_numeric_pipeline, basic_numeric_features),\n",
        "    ('log_num', log_numeric_pipeline, log_numeric_features),\n",
        "])\n",
        "\n",
        "\n",
        "full_pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(class_weight='balanced', random_state=42))\n",
        "])\n",
        "\n",
        "full_pipeline.set_output(transform=\"pandas\")\n",
        "_ = full_pipeline"
      ],
      "metadata": {
        "id": "YuWBOpigPL2G"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate model\n",
        "1. I used a locked cross-validation for a more robust deterministic evaluation.\n",
        "2. I applied the model to the hold-out test set to assess generalization.\n",
        "3. I generated feature importance with SHAP to better understand both the model and the data.\n",
        "\n"
      ],
      "metadata": {
        "id": "3s3Lvi7EZktX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "scoring = {\n",
        "    'accuracy': 'accuracy',\n",
        "    'precision': 'precision',\n",
        "    'recall': 'recall',\n",
        "    'f1': 'f1',\n",
        "    'roc_auc': 'roc_auc'\n",
        "}\n",
        "\n",
        "scores = cross_validate(\n",
        "    estimator=full_pipeline,\n",
        "    X=X_train,\n",
        "    y=y_train,\n",
        "    cv=cv,\n",
        "    scoring=scoring,\n",
        "    return_train_score=False\n",
        ")\n",
        "\n",
        "cv_results = pd.DataFrame(scores)\n",
        "\n",
        "print(\"Cross-Validation:\")\n",
        "for metric in scoring:\n",
        "    mean_score = cv_results[f'test_{metric}'].mean()\n",
        "    std_score = cv_results[f'test_{metric}'].std()\n",
        "    print(f\"{metric:>10}: {mean_score:.4f} ± {std_score:.4f}\")\n",
        "\n",
        "full_pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = full_pipeline.predict(X_val)\n",
        "y_proba = full_pipeline.predict_proba(X_val)[:, 1]\n",
        "\n",
        "print(\"Hold-out Set:\")\n",
        "print(f\"  Accuracy : {accuracy_score(y_val, y_pred):.4f}\")\n",
        "print(f\"  Precision: {precision_score(y_val, y_pred):.4f}\")\n",
        "print(f\"  Recall   : {recall_score(y_val, y_pred):.4f}\")\n",
        "print(f\"  F1 Score : {f1_score(y_val, y_pred):.4f}\")\n",
        "print(f\"  ROC AUC  : {roc_auc_score(y_val, y_proba):.4f}\")\n",
        "conf_mat = confusion_matrix(y_val, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_mat)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgo-hzEnPE3I",
        "outputId": "8151868d-485c-47af-ced0-caf2a1a4784d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation:\n",
            "  accuracy: 0.8035 ± 0.0472\n",
            " precision: 0.6680 ± 0.0753\n",
            "    recall: 0.7917 ± 0.0332\n",
            "        f1: 0.7236 ± 0.0563\n",
            "   roc_auc: 0.8845 ± 0.0305\n",
            "Hold-out Set:\n",
            "  Accuracy : 0.7833\n",
            "  Precision: 0.6875\n",
            "  Recall   : 0.5789\n",
            "  F1 Score : 0.6286\n",
            "  ROC AUC  : 0.8639\n",
            "\n",
            "Confusion Matrix:\n",
            "[[36  5]\n",
            " [ 8 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature importance"
      ],
      "metadata": {
        "id": "8Zzu7g7zFRe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for seed in [0, 10, 20, 30, 40]:\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X, y, test_size=0.2, stratify=y, random_state=seed\n",
        "    )\n",
        "    full_pipeline.fit(X_train, y_train)\n",
        "    y_pred = full_pipeline.predict(X_val)\n",
        "    print(f\"Seed {seed} - Recall: {recall_score(y_val, y_pred):.4f}\")\n",
        "\n",
        "preprocessor = full_pipeline.named_steps['preprocessor']\n",
        "model = full_pipeline.named_steps['classifier']\n",
        "\n",
        "X_val_transformed = preprocessor.transform(X_val)\n",
        "\n",
        "feature_names = X_val_transformed.columns\n",
        "\n",
        "explainer = shap.Explainer(model, X_val_transformed)\n",
        "shap_values = explainer(X_val_transformed)\n",
        "\n",
        "shap_importance = np.abs(shap_values.values).mean(axis=0)\n",
        "\n",
        "shap_df = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'mean_abs_shap': shap_importance\n",
        "})\n",
        "\n",
        "shap_df.sort_values(by='mean_abs_shap', ascending=False, inplace=True)\n",
        "\n",
        "shap_df.reset_index(drop=True, inplace=True)\n",
        "display(shap_df)"
      ],
      "metadata": {
        "id": "dNBg5U_JFTH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "In this field, false negatives are more dangerous than false positives, because a false negative could mean missing a high-risk patient possibly resulting in death. Therefore, recall is a key metric.\n",
        "\n",
        "What I learned from the metrics:\n",
        "1. The model is generalizing well. It performed well on the hold-out test set, because the dataset is relatively small, I tested the recall on 5 additional random seeds to ensure it wasn't a lucky split and the results held.\n",
        "2. The false negative rate is currently about 26%, which is reasonable, but should be further optimized in the final model to reduce the number of missed high-risk patients.\n",
        "3. The model significantly prioritized numeric features over binary ones. Among all features, time was the most significant factor, based on SHAP values."
      ],
      "metadata": {
        "id": "9z_BXXT0gBXM"
      }
    }
  ]
}