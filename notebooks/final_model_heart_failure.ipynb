{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Final Model - Random Forest"
      ],
      "metadata": {
        "id": "sffl7CeEHLIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator, TransformerMixin, OneToOneFeatureMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
        "from sklearn.metrics import (\n",
        "    make_scorer,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ],
      "metadata": {
        "id": "_mwzKDPfHSXp"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "q5AitOp5HCYv"
      },
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/CarsonShively/Heart-Failure/refs/heads/main/data/heart_failure.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "X = df.drop('DEATH_EVENT', axis=1)\n",
        "y = df['DEATH_EVENT']\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=99\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binary Features\n",
        "Simple NaN handling for initial building of final model."
      ],
      "metadata": {
        "id": "04riHX36HuNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binary_cols = [\n",
        "    'anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking'\n",
        "]\n",
        "\n",
        "zero_impute = [\n",
        "    'anaemia', 'diabetes', 'high_blood_pressure', 'smoking'\n",
        "]\n",
        "\n",
        "class BinaryInt64Cleaner(BaseEstimator, TransformerMixin, OneToOneFeatureMixin):\n",
        "    def __init__(self, binary_cols):\n",
        "        self.binary_cols = binary_cols\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        for col in self.binary_cols:\n",
        "            X[col] = pd.to_numeric(X[col], errors='coerce').astype('Int64')\n",
        "            X[col] = X[col].where(X[col].isin([0, 1]), pd.NA)\n",
        "        return X\n",
        "\n",
        "\n",
        "class BinaryImputer(BaseEstimator, TransformerMixin, OneToOneFeatureMixin):\n",
        "    def __init__(self, binary_cols, sex_col='sex'):\n",
        "        self.binary_cols = binary_cols\n",
        "        self.sex_col = sex_col\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.sex_mode_ = X[self.sex_col].mode(dropna=True)[0]\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        for col in self.binary_cols:\n",
        "            X[col] = X[col].fillna(0)\n",
        "        X[self.sex_col] = X[self.sex_col].fillna(self.sex_mode_)\n",
        "        return X\n",
        "\n",
        "class ConvertToInt(BaseEstimator, TransformerMixin, OneToOneFeatureMixin):\n",
        "    def __init__(self, columns):\n",
        "        self.columns = columns\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        for col in self.columns:\n",
        "            X[col] = X[col].astype(int)\n",
        "        return X\n",
        "\n",
        "\n",
        "binary_pipeline = Pipeline(steps=[\n",
        "    ('cleaner', BinaryInt64Cleaner(binary_cols=binary_cols)),\n",
        "    ('imputer', BinaryImputer(binary_cols=zero_impute, sex_col='sex')),\n",
        "    ('to_int', ConvertToInt(columns=binary_cols))\n",
        "])\n",
        "binary_pipeline.set_output(transform=\"pandas\")\n",
        "_ = binary_pipeline"
      ],
      "metadata": {
        "id": "aImj7NRCHwhr"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Numeric features\n",
        "\n",
        "Simple NaN and outlier hadnling for initial building of final model."
      ],
      "metadata": {
        "id": "JSKpGzyyJdjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_features = [\n",
        "    'age',\n",
        "    'creatinine_phosphokinase',\n",
        "    'ejection_fraction',\n",
        "    'platelets',\n",
        "    'serum_creatinine',\n",
        "    'serum_sodium',\n",
        "    'time',\n",
        "]\n",
        "\n",
        "class CoerceToFloat(BaseEstimator, TransformerMixin, OneToOneFeatureMixin):\n",
        "    def __init__(self, columns):\n",
        "        self.columns = columns\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        for col in self.columns:\n",
        "            X[col] = X[col].astype(float)\n",
        "        return X\n",
        "\n",
        "class NumericImputer(BaseEstimator, TransformerMixin, OneToOneFeatureMixin):\n",
        "    def __init__(self, columns):\n",
        "        self.columns = columns\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        X = X.copy()\n",
        "        self.medians_ = {\n",
        "            col: X[col].median(skipna=True)\n",
        "            for col in self.columns\n",
        "        }\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        for col in self.columns:\n",
        "            X[col] = X[col].fillna(self.medians_[col])\n",
        "        return X\n",
        "\n",
        "class OutlierClipper(BaseEstimator, TransformerMixin, OneToOneFeatureMixin):\n",
        "    def __init__(self, columns, lower_quantile=0.01, upper_quantile=0.99):\n",
        "        self.columns = columns\n",
        "        self.lower_quantile = lower_quantile\n",
        "        self.upper_quantile = upper_quantile\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        X = X.copy()\n",
        "        self.lower_bounds_ = {\n",
        "            col: X[col].quantile(self.lower_quantile) for col in self.columns\n",
        "        }\n",
        "        self.upper_bounds_ = {\n",
        "            col: X[col].quantile(self.upper_quantile) for col in self.columns\n",
        "        }\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        for col in self.columns:\n",
        "            X[col] = X[col].clip(self.lower_bounds_[col], self.upper_bounds_[col])\n",
        "        return X\n",
        "\n",
        "numeric_pipeline = Pipeline([\n",
        "    ('float', CoerceToFloat(columns=numeric_features)),\n",
        "    ('imputer', NumericImputer(columns=numeric_features)),\n",
        "    ('clip', OutlierClipper(columns=numeric_features)),\n",
        "])\n",
        "\n",
        "numeric_pipeline.set_output(transform=\"pandas\")\n",
        "_ = numeric_pipeline"
      ],
      "metadata": {
        "id": "RBQ9KrhKJgg_"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline"
      ],
      "metadata": {
        "id": "TeUUGNlsLUGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = ColumnTransformer([\n",
        "    ('bin', binary_pipeline, binary_cols),\n",
        "    ('num', numeric_pipeline, numeric_features)\n",
        "])\n",
        "\n",
        "preprocessor.set_output(transform='pandas')\n",
        "\n",
        "full_pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        class_weight='balanced',\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "full_pipeline.set_output(transform=\"pandas\")\n",
        "_ = full_pipeline"
      ],
      "metadata": {
        "id": "26Xw3EwILXtO"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial metrics"
      ],
      "metadata": {
        "id": "CGDKquoCP8fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "scoring = {\n",
        "    'accuracy': 'accuracy',\n",
        "    'precision': 'precision',\n",
        "    'recall': 'recall',\n",
        "    'f1': 'f1',\n",
        "    'roc_auc': 'roc_auc'\n",
        "}\n",
        "\n",
        "scores = cross_validate(\n",
        "    estimator=full_pipeline,\n",
        "    X=X_train,\n",
        "    y=y_train,\n",
        "    cv=cv,\n",
        "    scoring=scoring,\n",
        "    return_train_score=False\n",
        ")\n",
        "\n",
        "cv_results = pd.DataFrame(scores)\n",
        "\n",
        "print(\"Cross-Validation Performance:\")\n",
        "for metric in scoring:\n",
        "    mean_score = cv_results[f'test_{metric}'].mean()\n",
        "    std_score = cv_results[f'test_{metric}'].std()\n",
        "    print(f\"{metric:>10}: {mean_score:.4f} ± {std_score:.4f}\")\n",
        "\n",
        "full_pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = full_pipeline.predict(X_val)\n",
        "y_proba = full_pipeline.predict_proba(X_val)[:, 1]\n",
        "\n",
        "print(\"Test Set Evaluation:\")\n",
        "print(f\"  Accuracy : {accuracy_score(y_val, y_pred):.4f}\")\n",
        "print(f\"  Precision: {precision_score(y_val, y_pred):.4f}\")\n",
        "print(f\"  Recall   : {recall_score(y_val, y_pred):.4f}\")\n",
        "print(f\"  F1 Score : {f1_score(y_val, y_pred):.4f}\")\n",
        "print(f\"  ROC AUC  : {roc_auc_score(y_val, y_proba):.4f}\")\n",
        "conf_mat = confusion_matrix(y_val, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSWsveEBP-r0",
        "outputId": "ac06ee8e-b553-4fce-8b71-8363ba3f1133"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Performance:\n",
            "  accuracy: 0.8449 ± 0.0366\n",
            " precision: 0.8008 ± 0.0444\n",
            "    recall: 0.6858 ± 0.1152\n",
            "        f1: 0.7360 ± 0.0810\n",
            "   roc_auc: 0.9106 ± 0.0563\n",
            "Test Set Evaluation:\n",
            "  Accuracy : 0.8167\n",
            "  Precision: 0.7857\n",
            "  Recall   : 0.5789\n",
            "  F1 Score : 0.6667\n",
            "  ROC AUC  : 0.9101\n",
            "\n",
            "Confusion Matrix:\n",
            "[[38  3]\n",
            " [ 8 11]]\n"
          ]
        }
      ]
    }
  ]
}